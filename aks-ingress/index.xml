<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aks-ingresses on ASA Blog</title><link>https://asashiho.github.io/aks-ingress/</link><description>Recent content in Aks-ingresses on ASA Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>Your Copyright</copyright><lastBuildDate>Mon, 01 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://asashiho.github.io/aks-ingress/index.xml" rel="self" type="application/rss+xml"/><item><title>KubernetesクラスターでのWebアプリケーションゲートウェイ(Ingress)の構成について整理する</title><link>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</guid><description>前回のブログでは、Kubernetesクラスターに対するL4アクセス制御をAzure Kubernetes Serviceを例にして整理しました。
しかしながら、多くのケースではWebアプリケーションへの急激なトラフィックの増加やトランザクションの集中にも対応できるようにするだけでなく、バックエンドサーバー群に効率よくルーティングする機能やSSL終端、またDDoS攻撃からの防御やSQLインジェクションなどから保護するWeb Application FirewallなどL7でのアクセス制御が必要です。さらに流量制御や証明書管理などなど、さまざまな非機能要件があります。
で、基盤方式設計フェーズでは、これらの処理をだれがどこでどう行うか？の処理方式を検討しておく必要があるわけですが。。。
レジェンドな企業の多くの場合は、アプリケーション開発部門とインフラ構築部門、運用保守部門が組織として分かれているケースが多く、Webアプリケーションのゲートウェイ機能の方式設計は、インフラ構築部門が行い、共通基盤化してアプリ開発チームに引き渡し、運用フェーズになると運用保守部門にてメンテナンスすることがおおいでしょう。 大規模なシステムの場合、組織での責任分界点も踏まえたうえで、基盤方式設計を行うというのは極めて大事です。
システム内でKubernetesを利用する場合、L7ロードバランサの方式設計時に考慮しておくべきことがいくつかありますので、簡単なメモ書きとしてまとめます。
Kubernetes でのWebアプリケーションゲートウェイの構成パターン Kubernetes では、L7ロードバランシングを提供するとき、「Ingress」というリソースを使います。これは、HTTP やHTTPS の外部アクセスを制御するオブジェクトで、バーチャルホストやURLルーティング、ロードバランシング、SSL 終端などの機能を提供するものです。
Kubernetes のIngressには大きく分けて次の2つがあります。
クラスタ内でゲートウェイ処理を行うパターン これは、Kubernetes クラスター内でソフトウエアとしてWebアプリケーションゲートウェイの機能を動かすパターンです。Kubernetesクラスターからみるとコンテナアプリケーション(Pod)として動作し、これがミドルウエアの機能を果たします。
代表的なものがNginx Ingress Controller で、そのほかにもContour やContainous 社のTraefik、HAProxy などがあります。
クラスタ外でゲートウェイ処理を行うパターン ゲートウェイで処理したいもののなかには、SSL 終端のようにコンピューティングリソースを多く使うものもあったりします。 そのため、ゲートウェイ処理に特化したのものをクラスタ外部で動かし、クラスタとは疎結合にしておきたい！というニーズもあります。 普段オンプレをメインに担当されている方は、直感的に理解できるかと思います。
たとえばAzureの場合「Azure Application Gateway」という専用のサービスがあり、バックエンドがKuberbetes に限らずAzure 上の仮想マシンやオンプレなどのバックエンドもサポートできるものが提供されています。 またGCP の場合だと「Cloud Load Balancing」という最強サービスがあります。
これらを使ってバックエンドにKuberbetes クラスターをおいてあげれば、よさそうです。
Web アプリケーションゲートウェイの設定はどう運用するのか？ URLルーティングなどはアプリケーション開発者の関心ごとである一方、特にマルチクラウドでシステムを運用している場合、各クラウドごとに実装の異なるL7 ロードバランサーの操作手順をいちいち勉強するのはあまりテンションがあがるものではないでしょう。
しかもそれがものすごい勢いでアップデートしていくわけなので、だれかに任せたい気分になるとおもいます。
KubernetesでWeb アプリケーションゲートウェイの設定変更したり監視したりなどの運用保守を考えるとき、次の2つのパターンが考えられます。
運用管理者が行う方法 オンプレや仮想マシンベースのアーキテクチャの場合、URL ルーティングのポリシーの管理などはシステム変更があるたびにアプリケーション開発者からインフラ運用部門に変更依頼や承認などを経て、人間の手を介して本番環境へ反映するケースが多いと思います。
しかしながら、人間には信頼性がないことが広く知られています。
万全な冗長構成をとり基盤テストを繰り返して99.99999…を追求し、広域災害にも配慮した方式設計にすることでシステムの可用性もコストも高まり、クラウドベンダーは喜びます。しかしながら、SLAのない人間による手作業による温かみのあるURL ルーティングの設定変更がsingle point of failure になる可能性もありますので、運用方式設計にきちんと盛り込んでおきましょう！
が、すでに既存のシステムでなんらかのWeb アプリケーションゲートウェイを導入済みで、それらの運用スタイルが確立していて特に問題がないようであれば、使い慣れたものをそのまま利用するのもよいでしょう。
Azure の場合だと、すでにApplication Gateway を稼働中であればバックエンドサーバー群にAKS を配置してロードバランシングやルーティングなどを配置すればよいでしょう。なによりシステム構成がシンプルで直感的です。 アプリケーション開発者と運用保守エンジニアの心の距離が近い、または同一人物である、などの組織であれば、フレキシブルに対応できると思います。</description></item></channel></rss>