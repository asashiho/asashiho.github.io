<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>azure on ASA Blog</title><link>https://asashiho.github.io/categories/azure/</link><description>Recent content in azure on ASA Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>Your Copyright</copyright><lastBuildDate>Mon, 01 Jun 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://asashiho.github.io/categories/azure/index.xml" rel="self" type="application/rss+xml"/><item><title>KubernetesクラスターでのWebアプリケーションゲートウェイ(Ingress)の構成について整理する</title><link>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</guid><description>前回のブログでは、Kubernetesクラスターに対するL4アクセス制御をAzure Kubernetes Serviceを例にして整理しました。
しかしながら、多くのケースではWebアプリケーションへの急激なトラフィックの増加やトランザクションの集中にも対応できるようにするだけでなく、バックエンドサーバー群に効率よくルーティングする機能やSSL終端、またDDoS攻撃からの防御やSQLインジェクションなどから保護するWeb Application FirewallなどL7でのアクセス制御が必要です。さらに流量制御や証明書管理などなど、さまざまな非機能要件があります。
で、基盤方式設計フェーズでは、これらの処理をだれがどこでどう行うか？の処理方式を検討しておく必要があるわけですが。。。
レジェンドな企業の多くの場合は、アプリケーション開発部門とインフラ構築部門、運用保守部門が組織として分かれているケースが多く、Webアプリケーションのゲートウェイ機能の方式設計は、インフラ構築部門が行い、共通基盤化してアプリ開発チームに引き渡し、運用フェーズになると運用保守部門にてメンテナンスすることがおおいでしょう。 大規模なシステムの場合、組織での責任分界点も踏まえたうえで、基盤方式設計を行うというのは極めて大事です。
システム内でKubernetesを利用する場合、L7ロードバランサの方式設計時に考慮しておくべきことがいくつかありますので、簡単なメモ書きとしてまとめます。
Kubernetes でのWebアプリケーションゲートウェイの構成パターン Kubernetes では、L7ロードバランシングを提供するとき、「Ingress」というリソースを使います。これは、HTTP やHTTPS の外部アクセスを制御するオブジェクトで、バーチャルホストやURLルーティング、ロードバランシング、SSL 終端などの機能を提供するものです。
Kubernetes のIngressには大きく分けて次の2つがあります。
クラスタ内でゲートウェイ処理を行うパターン これは、Kubernetes クラスター内でソフトウエアとしてWebアプリケーションゲートウェイの機能を動かすパターンです。Kubernetesクラスターからみるとコンテナアプリケーション(Pod)として動作し、これがミドルウエアの機能を果たします。
代表的なものがNginx Ingress Controller で、そのほかにもContour やContainous 社のTraefik、HAProxy などがあります。
クラスタ外でゲートウェイ処理を行うパターン ゲートウェイで処理したいもののなかには、SSL 終端などのようにコンピューティングリソースを多く使うものもあったりします。 そのため、ゲートウェイ処理に特化したのものをクラスタ外部で動かし、クラスタとは疎結合にしておきたい！というニーズもあります。 普段オンプレをメインに担当されている方は、直感的に理解できるかと思います。
たとえばAzureの場合「Azure Application Gateway」という専用のサービスがあり、バックエンドがKuberbetes に限らずAzure 上の仮想マシンやオンプレなどのバックエンドもサポートできるものが提供されています。 またGCP の場合だと「Cloud Load Balancing」という最強サービスがあります。
これらを使ってバックエンドにKuberbetes クラスターをおいてあげれば、よさそうです。
Web アプリケーションゲートウェイの設定はどう運用するのか？ URLルーティングなどはアプリケーション開発者の関心ごとである一方、特にマルチクラウドでシステムを運用している場合、各クラウドごとに実装の異なるL7 ロードバランサーの操作手順をいちいち勉強するのはあまりテンションがあがるものではないでしょう。
しかもそれがものすごい勢いでアップデートしていくわけなので、だれかに任せたい気分になるとおもいます。
KubernetesでWeb アプリケーションゲートウェイの設定変更したり監視したりなどの運用保守を考えるとき、次の2つのパターンが考えられます。
運用管理者が行う方法 オンプレや仮想マシンベースのアーキテクチャの場合、URL ルーティングのポリシーの管理などはシステム変更があるたびにアプリケーション開発者からインフラ運用部門に変更依頼や承認などを経て、人間の手を介して本番環境へ反映するケースが多いと思います。
しかしながら、人間には信頼性がないことが広く知られています。
万全な冗長構成をとり基盤テストを繰り返して99.99999…を追求し、広域災害にも配慮した方式設計にすることでシステムの可用性もコストも高まり、クラウドベンダーは喜びます。しかしながら、SLAのない人間による手作業による温かみのあるURL ルーティングの設定変更がsingle point of failure になる可能性もありますので、運用方式設計にきちんと盛り込んでおきましょう！
が、しかし。すでに既存のシステムでなんらかのWeb アプリケーションゲートウェイを導入済みで、それらの運用スタイルが確立していて特に問題がないようであれば、使い慣れたものをそのまま利用するのもよいでしょう。
Azure の場合だと、すでにApplication Gateway を稼働中であればバックエンドサーバー群にAKS を配置してロードバランシングやルーティングなどを配置すればよいでしょう。なによりシステム構成がシンプルで直感的です。 アプリケーション開発者と運用保守エンジニアの心の距離が近い、または同一人物である、などの組織であれば、フレキシブルに対応できると思います。</description></item><item><title>Kubernetesクラスターに対するL4ネットワークアクセス制御を整理する</title><link>https://asashiho.github.io/aks-l4/kubernetes-l4/</link><pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/aks-l4/kubernetes-l4/</guid><description>お仕事でプリセールスをしているため、お客様やSIパートナー様といっしょに「高い安全性が求められるシステム」について議論することが多くあります。
いわゆるクラウドネイティブアプリケーションの場合、クラウド時代の脅威に対応するためには「 内部を（ユーザーも含めて）信頼しない 」という考え方を前提に考えることが適していたりします。
境界ベースのセキュリティからゼロトラスト セキュリティへの移行
従来のセキュリティ モデルでは、組織のアプリケーションはプライベート データセンターの外部ファイアウォールに依存して、受信トラフィックを保護できません。クラウド ネイティブ環境でも、BeyondCorp モデルと同様にネットワーク境界を引き続き保護する必要がありますが、境界ベースのセキュリティ モデルでは十分に保護できません。新しいセキュリティ上の問題が発生するわけではありませんが、ファイアウォールで企業ネットワークを完全に保護できなければ、本番環境ネットワークも完全に保護できません。ゼロトラスト セキュリティ モデルでは、内部トラフィックが暗黙に信頼されず、認証や暗号化などのセキュリティ制御が必要になります。同時に、マイクロサービスへの移行は、従来のセキュリティ モデルを再検討する機会となります。単一のネットワーク境界（1 つのファイアウォールなど）への依存を排除すると、ネットワークをサービスごとに分割できるようになります。このアイデアをさらに進めて、サービス間に固有の相互信頼関係をなくして、マイクロサービス レベルのセグメンテーションを実装することもできます。マイクロサービスでは、トラフィックの信頼度がさまざまであるため、内部トラフィックと外部トラフィックを比較するだけでは済みません。
引用:BeyondProd: クラウド ネイティブ セキュリティに対する新しいアプローチより
とはいうものの、、、オンプレミス環境などでシステムを運用しているケースでは境界型モデルが馴染みが深く、まず最初に方式設計の検討テーマに上がります。
このブログでは、Kubernetesクラスターへのネットワークアクセスについて私自身が検証していて気づいたことをホワイトボードに書く感覚で、だらだらと書きとめます。
※ なお「Kuberntesのセキュリティ対策はネットワークアクセス制御さえすれば安全といえよう！」のようなシンプルなものではなく、認証認可・イメージの脆弱性検査・特権エスカレーションの阻止などなどなどなどなど、多岐にわたります。Kuberntesに対する脅威はこちらの「Attack matrix for Kubernetes」にまとまっておりますので、ぜひ。
Kubernetesクラスターへの2つのアクセス経路 Kubernetesクラスターを運用環境で稼働させるとき、安全なアクセス経路を検討するには、次の2つを考える必要があります。
なお、分かりやすさ重視のため「ほげ銀行」という妄想上の企業の社内システムを例に説明しています。
1. Kubernetesクラスター上で動かすアプリに対するアクセス 主にシステム利用者がKubernetesクラスター上で動くWebアプリケーションにアクセスするときのアクセス経路です。たとえば、ほげ銀行では市場国際部門・与信管理部門・証券投資部門のユーザがそれぞれの業務を行うためのアプリケーションにアクセスします。
2. Kubernetesクラスター管理のためのコントロープレーンに対するアクセス Kubernetesクラスターへのアプリのデプロイやクラスターの運用などでKubernetesのAPI Serverに対してアクセスするための経路です。クラスターに対して強い権限が必要になるため、限られたアクセス経路からのみ通信できる必要があります。
今回のブログは、1.のケースのアクセス経路についてのみ整理します。
(この話をごちゃごちゃ混乱させずに文章で説明する能力がないので2.のプライベートクラスターのケースについては、別ブログにて改めて)
境界型モデルによるネットワークアクセスコントロール 従来のオンプレミス型のシステムの場合、業務システムへのアクセスは、すべてのトラフィックをFWを介してコントロールする場合が多いと思います。
基本的に社内システムはプライベートな閉塞区間で運用し、社外への通信が必要な場合はバリアセグメントを設け、そこを経由することでアクセスコントロール・監査・Lockdownを1か所で行う、という考え方です。
たとえば、Azureの場合、Azure Kubernetes Service(AKS)のアクセス制御するときは以下のようなアーキテクチャになります。
このクラスタ外に配置したAzure Firewallの主な目的は、組織がAKSクラスターに対して細かくIngressおよびEgress Traffic規則を設定できるようにすることです。
たとえばこの構成例では、Ingress Trafficはファイアウォール フィルターの経由が強制されています。 またEgress Trafficはユーザー定義ルートを使用して、NodeからAzure FirewallのInternal IPを介して、パブリックインターネットまたはその他のAzureサービスへのアクセスは、FWのPublic IPで行われます。
またAKSの場合、クラスターが機能するには、必須のEgress Endpointで定義されているすべてのEndpointをアプリケーション ファイアウォール規則で有効にする必要があります。 これらのエンドポイントが有効ではない場合、クラスターは正しく動かないので注意してください。
az network firewall application-rule create -g $RG -f $FWNAME \ --collection-name &amp;#39;AKS_Global_Required&amp;#39; \ --action allow \ --priority 100 \ -n &amp;#39;required&amp;#39; \ --source-addresses &amp;#39;*&amp;#39; \ --protocols &amp;#39;http=80&amp;#39; &amp;#39;https=443&amp;#39; \ --target-fqdns \ &amp;#39;aksrepos.</description></item></channel></rss>