<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ASA Blog</title><link>https://asashiho.github.io/</link><description>Recent content on ASA Blog</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>Your Copyright</copyright><lastBuildDate>Thu, 30 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://asashiho.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Kubernetes上で動くアプリのバージョンアップ、裏側でなにがおこっているのか</title><link>https://asashiho.github.io/kubernetes-deployment/kubernetes-deployment/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/kubernetes-deployment/kubernetes-deployment/</guid><description>最近業務でお手伝いさせていただく案件のなかでも、Java on Kubernetesなパターンが増えてきています。Kubernetesに限らずクラウドのマネージドPaaSで動かすにはアプリケーション側でもクラウドネイティブを考慮した実装が必要になり、特に耐障害性や回復性などを意識した実装が大事になってきます。
アプリケーションのリリース方式も、オンプレでのWeb3層システムとは考え方が異なる部分やKubernetesのしくみを正しく理解しておく必要があるので、あらためて整理したいと思います。
アプリのバージョンアップ アプリケーション開発の世界では、1度リリース完了したらそれで終わりではなく、新機能追加やバグ修正などによりバージョンアップが行われます。特にビジネス要件の変更が頻繁なケースでは、小さな単位でアプリケーションの機能追加/修正し、短いタイミングでリリースする手法が使われています。
しかしながら、アプリケーションのバージョンアップには危険を伴います。ちょっとした設定ミスによりシステムエラーをおこし、場合によってはサービス停止に至ることもあるでしょう。したがって、テスト済みの安全なものを、なるべく迅速に本番環境にデプロイできるしくみを整えることが大事です。
アプリケーションを本番環境にデプロイする手法はいくつかありますが、代表的なものは次の2つです。
ローリングアップデート アプリケーションをバージョンアップする際に、まとめて一気に変更するのではなく、稼動状態のまま少しずつ順番に更新する手法です。同じアプリケーションが複数並列に動いている場合に徐々に入れ替えていくので、バージョンアップ中は新旧のアプリケーションが混在することになります。そのためアプリケーションがローリングアップデートに対応している必要があります。
ブルー/グリーンデプロイメント バージョンの異なる新旧2つのアプリケーションを同時に起動させておき、ネットワークの設定変更で変更する方法です。ブルー（旧）とグリーン（新）を切り替えることから、ブルー/グリーンデプロイメントと呼ばれます。 ブルーが本番としてサービス提供しているときには、グリーンは待機している状態となります。新機能は、待機系であるグリーン側に追加して、こちらで事前テストを実施します。そしてテストをクリアしたことを確認したうえでグリーンを本番に切り替えます。この方式はもし切り替えたグリーンのアプリケーションで障害があったときに、即座にブルーに切り戻せるというメリットがあります。
このほかにも、一部の利用者にのみ新機能を提供し、問題がないことを確認してから全ユーザに大規模展開するカナリアリリースなどもあります。
Deploymentを使ったアプリのバージョンアップ Kubernetesには、安全にアプリをアップデートするしくみが備わっていて「Deployment」と呼ばれています。
この、Deploymentリソースには、大きく分けて次の2つのアップデートの処理方式があります。これは、マニフェストファイルのDeploymentのspec-strategy-typeで設定し、デフォルトはRollingUpdateです。
spec: strategy: type: Recreate Recrate いったん古いPodをすべて停止し、新しいPodを再作成する方式です。シンプルで高速に動きますが、ダウンタイムが発生します。開発環境やダウンタイムが許容できるシステムなどで使います。
RollingUpdate クラスターで動くPodを少しずつアップデートしていく方式です。古いPodが動いている状態で、新しいPodを起動し、新しいPodの起動が確認出来たら古いPodを停止するという動きをします。一時的に新旧のバージョンが混在するので処理方法は複雑になりますが、ダウンタイムなしで移行できるのが特徴です。本番環境ではこちらを採用するのが良いでしょう。
DeploymentによるRollingUpdate ここではDeploymentリソースのデフォルトになっているRollingUpdateによるバージョンアップの挙動をみていきます。
ロールアウト ロールアウトとは、アプリケーションをクラスター内にデプロイし、サービスを稼働させることです。
ここで、次のDeploymentを作成します。
apiVersion: apps/v1 kind: Deployment metadata: labels: app: front name: front spec: replicas: 3 strategy: type: RollingUpdate selector: matchLabels: app: front template: metadata: labels: app: front spec: containers: - image: xxx/frontend:v1.0.0 name: front 次のコマンドを実行すると、クラスタにfrontend:v1.0.0がデプロイされます。</description></item><item><title>Spring WebFlux + KuberntesでアプリのGraceful Shutdownを実装する</title><link>https://asashiho.github.io/spring-graceful/spring-graceful/</link><pubDate>Thu, 30 Sep 2021 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/spring-graceful/spring-graceful/</guid><description>最近業務でお手伝いさせていただく案件のなかでも、Java on Kubernetesなパターンが増えてきています。Kubernetesに限らずクラウドのマネージドPaaSで動かすにはアプリケーション側でもクラウドネイティブを考慮した実装が必要になり、特に耐障害性や回復性などを意識した実装が大事になってきます。
クラウドネイティブな環境でアプリケーションを動かすときに、開発者の観点でどういうところに注意すればよいかは
通信先のサービス(DB/外部API)は常に動いていると思うべからず 死に際を美しく(Graceful Shutdown) 秘匿情報・環境依存値の取り扱い ステートレスにすべし あたりが大事なポイントになってくるかなと思っています。
このエントリでは、2つ目の
死に際を美しく(Graceful Shutdown)
対策の一つであるアプリケーションのGraceful Shutdownの実装について、Spring Bootを使った実装の例を説明します。
そもそも、Graceful Shutdownとは？ 従来のオンプレでのWeb3層システムの場合、システムメンテナンスなどでWebサーバを停止させる場合、システム運用者によって次の作業を行います。
LBで該当Webサーバへの新規リクエストの受付を停止する 該当Webサーバ上で動くアプリケーションが処理し終わるのを待つ 処理中のプロセスが無いことを確認できたら、Webサーバを停止する クラウドネイティブな構成の場合、これらの処理をソフトウエアで自動化しています。たとえば、Kubernetesの場合、LBに相当するService/IngressからWebアプリケーションに相当するPodへのルーティングを宣言ベースで行い、クラスタの状態を維持します。またプラットフォームのメンテナンス等でPodが動いているWorker Nodeが移動するケースも普通にあります。また、Deploymentの更新などの理由でPodの再作成やPodの終了処理がいたるところで行われます。
これらは基盤メンテチーム側からみると「Kubernetesのしくみをつかって工数のかかるWebサーバのメンテナンスを自動化した！生産性向上！ゆっくり眠れる！！最高！！！！」となります。
一方のアプリ開発チーム側から見ると「Kubernetesが勝手にWebサーバ再起動した！！！こっちはサービス提供時間中だぞ！！！ひどい！！！今までは1台ずつ丁寧に夜間手作業でやってくれてたじゃないか！！！」
そしてここではじめて、システム運用者のありがたみを心から知ることになります。
つまり、、、、、このような悲惨なすれ違いをなくすには 「今までシステム運用者がやっていた1-3の作業はどうなる？」 を深堀りしたアプリケーション方式設計/基盤方式設計が必要だということがわかります。
Graceful Shutdownとは、アプリケーションをシャットダウンする前に、まだ進行中の要求を完了するためのタイムアウト期間を設け、その間に安全にアプリケーションを終了させることです。タイムアウト期間中に、すでに動いているアプリの処理の終了やDBなど外部サービスへの接続を停止する処理を行い、それが完了したらシャットダウンを行うことでデータのロストやコネクションのクローズ処理、アプリ不整合やエラーを防ぐことができます。
Spring boot 2.3.0.RELEASE以降では、フレームワーク自体にGraceful Shutdownの機能が追加されました。この機能は現在Tomcat/Undertow/Netty/JettyのWebサーバで提供されており、SmartLifecycleBeanを停止する最初のフェーズで実行されます。
なおアプリケーションが新しい要求を停止する方法は、Webサーバによって異なりますが公式ドキュメントによると、Tomcat/Jetty/Nettyはネットワーク層でのリクエストの受け入れを停止し、Undertowはリクエストを受け入れるもののHTTP503で応答します。
Graceful Shutdown
では、具体的な実装例を見ていきましょう。
Spring WebFlux/NettyでのGraceful Shutdown Spring WebFluxは、NettyなどのノンブロッキングI/Oベースのアプリケーションサーバ上で動作します。そして、ネットワークアクセスやDBアクセスなどのI/O処理の呼び出しに対して、1つのスレッドで複数のリクエストを処理でき少ないスレッドで実行できるため、メモリサイズやCPUの使用を減らすことが可能です。
Spring WebFluxでは、Reactorによるリアクティブプログラミングを採用しています。リアクティブプログラミングとは、データに着目したイベント駆動型のプログラミングの一種で、通知されるデータを受け取って処理を行うハンドラを実装することによって連続的なデータを処理する手法です。Reactorはリアクティブプログラミングを実現するためのライブラリの一つであり、ノンブロッキングで非同期なリアクティブプログラミングの仕組みを提供しています。
Spring WebFluxによるWebアプリケーションの作成 Spring WebFluxを使ったWebアプリケーションは「Spring Initializr」を使ってプロジェクトのひな型を作成できます。その際、[ADD DEPENDENCIES]で[Spring Reactive Web]と[Spring Boot Actuator]を追加します。
ダウンロードしたZIPのpom.xmlを確認すると以下のdependencyが登録されています。
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-webflux&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.</description></item><item><title>Spring WebFlux + WebClientでリトライ処理を実装する</title><link>https://asashiho.github.io/spring-webflux-retry/spring-webflux-retry/</link><pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/spring-webflux-retry/spring-webflux-retry/</guid><description>最近業務でお手伝いさせていただく案件のなかでも、Java on Kubernetesなパターンが増えてきています。Kubernetesに限らずクラウドのマネージドPaaSで動かすにはアプリケーション側でもクラウドネイティブを考慮した実装が必要になり、特に耐障害性や回復性などを意識した実装が大事になってきます。
クラウドネイティブなアプリケーション方式設計されたシステムでは、大きな問題もなく開発者からみると「クラウド超便利」「マネージド最高か！」となりますが、ごくまれに「オンプレで動いていたそのままのアプリをクラウドに持ってきた」or「オンプレを前提とした開発手法で実装されたレガシーアプリをクラウドネイティブなPaaSサービスで動かしてみた」というケースで問題が発生することがあります。
クラウドネイティブな環境でアプリケーションを動かすときに、開発者の観点でどういうところに注意すればよいかは、来月中にきちんとまとめる予定ですが
通信先のサービス(DB/外部API)は常に動いていると思うべからず 死に際を美しく(Graceful Shutdown) 秘匿情報・環境依存値の取り扱い ステートレスにすべし あたりが大事なポイントになってくるかなと思っています。
このエントリでは、１つ目の
通信先のサービス(DB/外部API)は常に動いていると思うべからず
対策の一つであるアプリケーションのリトライ処理の実装について、Spring WebFluxのWebClientを使った実装の例を説明します。
そもそも、リトライ処理とは？ クラウドとは？を開発者のみなさんに一言で説明すると、以下のとおりです。
「クラウド事業者が運用している巨大インフラ(サーバ/ネットワーク/ストレージ)を利用できるサービス。利用するにはAPIをCallするだけ、利用料金は従量課金、SLAが規定値を下回ったら返金 」
たとえば99.99%のクラウドサービスを利用した場合、1か月のうち、4.3分は停止する可能性があります。それが月次の定期メンテナンスのタイミング/深夜のユーザ利用率の低い時間帯/優先度の低いシステムであれば大きな問題にはならないかもしれません。しかし相手は機械。空気を読むことはしません。金融システムにおける五十日の決済処理のような場合も十分にありえます。あとは分かるな？
SLA 停止時間(月) 99.9% 43分 99.95% 21分 99.99% 4.3分 99.999% 25.8秒 そもそも、クラウドでなくとも多数のコンポーネントから構成される大規模分散システムでは系内の障害をゼロにすることは不可能なため、障害をゼロにしよう！というアプローチではなく、回復性を高めよう！という観点でのアプリケーション処理方式の一つとしてリトライ処理を実装されてきたとおもいます。特にミッションクリティカル系システムでは、いにしえより必ず検討されてきた方式なので、令和の今あらためての新鮮味はないでしょう。
とはいえ、リトライ処理とは文字通り「リクエストを再試行する」ものなのですが、いつ、だれが、どこで、どうやってリトライを行えばいいのかはむずかしい問題です。
Exponential backoff and jitter ―― 指数関数的バックオフとジッター リクエストもまばらでの規模が小さい場合は、n秒ごとに再試行する、などの固定値で実装するケースもあるかとおもいますが、大規模ミッションクリティカルシステムの場合データセンター障害のような大規模なトラブル時を考慮する必要があります。大規模障害時は多くのサーバ/サービスが停止していると想定されます。そのため、多数のクライアントからのリクエストがエラーになり、結果的に多数のリトライが送信されることになります。
このとき、クライアント側で固定値でリトライ処理を実装すると、全クライアントがn秒ごとに同じタイミングでリトライ処理を実施することになります。API側からみると、n秒ごとに多数のリクエストに受けることになり、過剰な負荷がかかることになります。さらにリトライストームでカスケード障害を引き起こす可能性もあります。
そのため、リトライする間隔が大事になってきます。どのような間隔でリトライを行えば、系全体でみたときに効率的なのかを解決する手法として、「Exponential backoff and jitter」という有名なリトライのアルゴリズムがあります。
Exponential backoffは、処理が失敗した後のリトライする間隔を許容可能な範囲で徐々に減らしつつ継続するアルゴリズムです。具体的には、再試行する度に、1秒後、2秒後、4秒後と指数関数的に待ち時間を長くしていきます。これにより、全体のリトライ回数を抑え、リクエストが殺到するのを防ぎます。
一般的に分散システムでは複数のコンポーネントが協調して動作します。そのためリトライのタイミングをわざとずらして衝突を回避させるために、random関数を用いたjitterというゆらぎをいれます。
ちなみにAzureでは一時障害がなぜ発生するのか？どう対処すればよいか、アンチパターンは？などのガイダンスがまとまっておりますので、ぜひ。2016年のドキュメントですが、色褪せない内容になっています。 Transient fault handling</description></item><item><title>Azure AppServiceでOpenID Connect プロバイダーを使用してログインする</title><link>https://asashiho.github.io/appservice-oidc/appservice-oidc/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/appservice-oidc/appservice-oidc/</guid><description>※ 本エントリーは2021/09時点の内容になります。現在プレビュー機能のため内容が変更になる場合があります。
AzureのAppServiceは、認証プロバイダとしてAzure AD/Facebook/Google/Twitterに加えて、OpenID Connectを選ぶことができます。 このエントリーは、OpenID Connect の仕様に準拠したカスタム認証プロバイダーを使用してAzure App Servicesを構成する方法を説明します。
KeyCloakでOpenID Connectプロバイダーを構築する まずはじめに機能検証を行うために、OpenID Connectプロバイダーを構築します。既存のIDプロバイダーがある場合はそちらを使ってください。
KeyCloakの検証環境構築 ここでは、Azure Container InstanceとKeyCloakを使って簡易的なIDプロバイダを作成します。
まず、Azureの東日本リージョンにリソースグループを作成します
az login RG_NAME=keycloak ACI_NAME=keycloak az group create -n $RG_NAME -l japaneast Azure Container Instanceは(ACI)、Azureが提供するコンテナ実行環境サービスです。 次のコマンドを実行してKeyCloakをAzure Container Instanceを起動します。 ここで、'&amp;ndash;environment-variablesオプション&amp;rsquo; でKeyCloakの管理者ユーザ名を&amp;rsquo;KEYCLOAK_USER&amp;rsquo;、パスワードを&amp;rsquo;KEYCLOAK_PASSWORD'に設定します。
az container create \ -g $RG_NAME \ -n $ACI_NAME \ --image jboss/keycloak \ --dns-name-label aci-keycloak \ --ports 8080 \ --environment-variables &amp;#39;KEYCLOAK_USER&amp;#39;=&amp;#39;admin&amp;#39; &amp;#39;KEYCLOAK_PASSWORD&amp;#39;=&amp;#39;password&amp;#39; 次のコマンドを実行すると、ACIの完全修飾ドメイン名(FQDN)とそのプロビジョニング状態が表示されます。
az container show \ -g $RG_NAME \ -n $ACI_NAME \ --query &amp;#34;{FQDN:ipAddress.</description></item><item><title>Durable functions on Kubernetes</title><link>https://asashiho.github.io/durable-on-aks/durable-on-aks/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/durable-on-aks/durable-on-aks/</guid><description>Durable Functions は、サーバーレスでステートフル関数を記述できる Azure Functionsの拡張機能です。人類の念願だったPythonもサポートされ、業務で使う機会がありましたので、ざっと動作検証しました。
Durable Functions とは Durable Functionsの主な利用シナリオは、サーバーレスアプリケーションにおける複雑でステートフルな処理を簡単に実装できるものです。
Azure FunctionがサポートするトリガーはAzure Functions でのトリガーとバインドの概念にて。
よく使いそうな処理は以下の通りです。
関数チェーン 関数チェーンは、一連の関数が特定の順序で実行されます。 このパターンでは、ある関数の出力が、別の関数の入力に適用されます。たとえば、F1、F2、F3、F4 という関数を逐次処理させたいときは 通常の命令型のコーディング構造を使用して、制御フローを実装できます。 コードは、上から下に実行され条件文やループなどの制御フローを含めることができます。またtry/catch/finally ブロックに、エラー処理ロジックを含めることができます。
たとえば、contextオブジェクトを使用して、他の関数を名前で呼び出し、パラメーターを渡して、関数の出力を返すことができます。 コードがyieldを呼び出すたびに Durable Functionsは、チェックポイントを設定します。
import azure.functions as func import azure.durable_functions as df def orchestrator_function(context: df.DurableOrchestrationContext): x = yield context.call_activity(&amp;#34;F1&amp;#34;, None) y = yield context.call_activity(&amp;#34;F2&amp;#34;, x) z = yield context.call_activity(&amp;#34;F3&amp;#34;, y) result = yield context.call_activity(&amp;#34;F4&amp;#34;, z) return result main = df.Orchestrator.create(orchestrator_function) ファンアウト/ファンイン 複数の関数を並列で実行し、すべての関数が完了するまで待機できます。複数の関数から返される結果に基づいて集計作業などを行うときに使うと便利です。
import azure.functions as func import azure.</description></item><item><title>KubernetesクラスターでのWebアプリケーションゲートウェイ(Ingress)の構成について整理する</title><link>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</link><pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/aks-ingress/kubernetes-ingress/</guid><description>前回のブログでは、Kubernetesクラスターに対するL4アクセス制御をAzure Kubernetes Serviceを例にして整理しました。
しかしながら、多くのケースではWebアプリケーションへの急激なトラフィックの増加やトランザクションの集中にも対応できるようにするだけでなく、バックエンドサーバー群に効率よくルーティングする機能やSSL終端、またDDoS攻撃からの防御やSQLインジェクションなどから保護するWeb Application FirewallなどL7でのアクセス制御が必要です。さらに流量制御や証明書管理などなど、さまざまな非機能要件があります。
で、基盤方式設計フェーズでは、これらの処理をだれがどこでどう行うか？の処理方式を検討しておく必要があるわけですが。。。
レジェンドな企業の多くの場合は、アプリケーション開発部門とインフラ構築部門、運用保守部門が組織として分かれているケースが多く、Webアプリケーションのゲートウェイ機能の方式設計は、インフラ構築部門が行い、共通基盤化してアプリ開発チームに引き渡し、運用フェーズになると運用保守部門にてメンテナンスすることがおおいでしょう。 大規模なシステムの場合、組織での責任分界点も踏まえたうえで、基盤方式設計を行うというのは極めて大事です。
システム内でKubernetesを利用する場合、L7ロードバランサの方式設計時に考慮しておくべきことがいくつかありますので、簡単なメモ書きとしてまとめます。
Kubernetes でのWebアプリケーションゲートウェイの構成パターン Kubernetes では、L7ロードバランシングを提供するとき、「Ingress」というリソースを使います。これは、HTTP やHTTPS の外部アクセスを制御するオブジェクトで、バーチャルホストやURLルーティング、ロードバランシング、SSL 終端などの機能を提供するものです。
Kubernetes のIngressには大きく分けて次の2つがあります。
クラスタ内でゲートウェイ処理を行うパターン これは、Kubernetes クラスター内でソフトウエアとしてWebアプリケーションゲートウェイの機能を動かすパターンです。Kubernetesクラスターからみるとコンテナアプリケーション(Pod)として動作し、これがミドルウエアの機能を果たします。
代表的なものがNginx Ingress Controller で、そのほかにもContour やContainous 社のTraefik、HAProxy などがあります。
クラスタ外でゲートウェイ処理を行うパターン ゲートウェイで処理したいもののなかには、SSL 終端のようにコンピューティングリソースを多く使うものもあったりします。 そのため、ゲートウェイ処理に特化したのものをクラスタ外部で動かし、クラスタとは疎結合にしておきたい！というニーズもあります。 普段オンプレをメインに担当されている方は、直感的に理解できるかと思います。
たとえばAzureの場合「Azure Application Gateway」という専用のサービスがあり、バックエンドがKuberbetes に限らずAzure 上の仮想マシンやオンプレなどのバックエンドもサポートできるものが提供されています。 またGCP の場合だと「Cloud Load Balancing」という最強サービスがあります。
これらを使ってバックエンドにKuberbetes クラスターをおいてあげれば、よさそうです。
Web アプリケーションゲートウェイの設定はどう運用するのか？ URLルーティングなどはアプリケーション開発者の関心ごとである一方、特にマルチクラウドでシステムを運用している場合、各クラウドごとに実装の異なるL7 ロードバランサーの操作手順をいちいち勉強するのはあまりテンションがあがるものではないでしょう。
しかもそれがものすごい勢いでアップデートしていくわけなので、だれかに任せたい気分になるとおもいます。
KubernetesでWeb アプリケーションゲートウェイの設定変更したり監視したりなどの運用保守を考えるとき、次の2つのパターンが考えられます。
運用管理者が行う方法 オンプレや仮想マシンベースのアーキテクチャの場合、URL ルーティングのポリシーの管理などはシステム変更があるたびにアプリケーション開発者からインフラ運用部門に変更依頼や承認などを経て、人間の手を介して本番環境へ反映するケースが多いと思います。
しかしながら、人間には信頼性がないことが広く知られています。
万全な冗長構成をとり基盤テストを繰り返して99.99999…を追求し、広域災害にも配慮した方式設計にすることでシステムの可用性もコストも高まり、クラウドベンダーは喜びます。しかしながら、SLAのない人間による手作業による温かみのあるURL ルーティングの設定変更がsingle point of failure になる可能性もありますので、運用方式設計にきちんと盛り込んでおきましょう！
が、すでに既存のシステムでなんらかのWeb アプリケーションゲートウェイを導入済みで、それらの運用スタイルが確立していて特に問題がないようであれば、使い慣れたものをそのまま利用するのもよいでしょう。
Azure の場合だと、すでにApplication Gateway を稼働中であればバックエンドサーバー群にAKS を配置してロードバランシングやルーティングなどを配置すればよいでしょう。なによりシステム構成がシンプルで直感的です。 アプリケーション開発者と運用保守エンジニアの心の距離が近い、または同一人物である、などの組織であれば、フレキシブルに対応できると思います。</description></item><item><title>Kubernetesクラスターに対するL4ネットワークアクセス制御を整理する</title><link>https://asashiho.github.io/aks-l4/kubernetes-l4/</link><pubDate>Fri, 08 May 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/aks-l4/kubernetes-l4/</guid><description>お仕事でプリセールスをしているため、お客様やSIパートナー様といっしょに「高い安全性が求められるシステム」について議論することが多くあります。
いわゆるクラウドネイティブアプリケーションの場合、クラウド時代の脅威に対応するためには「 内部を（ユーザーも含めて）信頼しない 」という考え方を前提に考えることが適していたりします。
境界ベースのセキュリティからゼロトラスト セキュリティへの移行
従来のセキュリティ モデルでは、組織のアプリケーションはプライベート データセンターの外部ファイアウォールに依存して、受信トラフィックを保護できません。クラウド ネイティブ環境でも、BeyondCorp モデルと同様にネットワーク境界を引き続き保護する必要がありますが、境界ベースのセキュリティ モデルでは十分に保護できません。新しいセキュリティ上の問題が発生するわけではありませんが、ファイアウォールで企業ネットワークを完全に保護できなければ、本番環境ネットワークも完全に保護できません。ゼロトラスト セキュリティ モデルでは、内部トラフィックが暗黙に信頼されず、認証や暗号化などのセキュリティ制御が必要になります。同時に、マイクロサービスへの移行は、従来のセキュリティ モデルを再検討する機会となります。単一のネットワーク境界（1 つのファイアウォールなど）への依存を排除すると、ネットワークをサービスごとに分割できるようになります。このアイデアをさらに進めて、サービス間に固有の相互信頼関係をなくして、マイクロサービス レベルのセグメンテーションを実装することもできます。マイクロサービスでは、トラフィックの信頼度がさまざまであるため、内部トラフィックと外部トラフィックを比較するだけでは済みません。
引用:BeyondProd: クラウド ネイティブ セキュリティに対する新しいアプローチより
とはいうものの、、、オンプレミス環境などでシステムを運用しているケースでは境界型モデルが馴染みが深く、まず最初に方式設計の検討テーマに上がります。
このブログでは、Kubernetesクラスターへのネットワークアクセスについて私自身が検証していて気づいたことをホワイトボードに書く感覚で、だらだらと書きとめます。
※ なお「Kuberntesのセキュリティ対策はネットワークアクセス制御さえすれば安全といえよう！」のようなシンプルなものではなく、認証認可・イメージの脆弱性検査・特権エスカレーションの阻止などなどなどなどなど、多岐にわたります。Kuberntesに対する脅威はこちらの「Attack matrix for Kubernetes」にまとまっておりますので、ぜひ。
Kubernetesクラスターへの2つのアクセス経路 Kubernetesクラスターを運用環境で稼働させるとき、安全なアクセス経路を検討するには、次の2つを考える必要があります。
なお、分かりやすさ重視のため「ほげ銀行」という妄想上の企業の社内システムを例に説明しています。
1. Kubernetesクラスター上で動かすアプリに対するアクセス 主にシステム利用者がKubernetesクラスター上で動くWebアプリケーションにアクセスするときのアクセス経路です。たとえば、ほげ銀行では市場国際部門・与信管理部門・証券投資部門のユーザがそれぞれの業務を行うためのアプリケーションにアクセスします。
2. Kubernetesクラスター管理のためのコントロープレーンに対するアクセス Kubernetesクラスターへのアプリのデプロイやクラスターの運用などでKubernetesのAPI Serverに対してアクセスするための経路です。クラスターに対して強い権限が必要になるため、限られたアクセス経路からのみ通信できる必要があります。
今回のブログは、1.のケースのアクセス経路についてのみ整理します。
(この話をごちゃごちゃ混乱させずに文章で説明する能力がないので2.のプライベートクラスターのケースについては、別ブログにて改めて)
境界型モデルによるネットワークアクセスコントロール 従来のオンプレミス型のシステムの場合、業務システムへのアクセスは、すべてのトラフィックをFWを介してコントロールする場合が多いと思います。
基本的に社内システムはプライベートな閉塞区間で運用し、社外への通信が必要な場合はバリアセグメントを設け、そこを経由することでアクセスコントロール・監査・Lockdownを1か所で行う、という考え方です。
たとえば、Azureの場合、Azure Kubernetes Service(AKS)のアクセス制御するときは以下のようなアーキテクチャになります。
このクラスタ外に配置したAzure Firewallの主な目的は、組織がAKSクラスターに対して細かくIngressおよびEgress Traffic規則を設定できるようにすることです。
たとえばこの構成例では、Ingress Trafficはファイアウォール フィルターの経由が強制されています。 またEgress Trafficはユーザー定義ルートを使用して、NodeからAzure FirewallのInternal IPを介して、パブリックインターネットまたはその他のAzureサービスへのアクセスは、FWのPublic IPで行われます。
またAKSの場合、クラスターが機能するには、必須のEgress Endpointで定義されているすべてのEndpointをアプリケーション ファイアウォール規則で有効にする必要があります。 これらのエンドポイントが有効ではない場合、クラスターは正しく動かないので注意してください。
az network firewall application-rule create -g $RG -f $FWNAME \ --collection-name &amp;#39;AKS_Global_Required&amp;#39; \ --action allow \ --priority 100 \ -n &amp;#39;required&amp;#39; \ --source-addresses &amp;#39;*&amp;#39; \ --protocols &amp;#39;http=80&amp;#39; &amp;#39;https=443&amp;#39; \ --target-fqdns \ &amp;#39;aksrepos.</description></item><item><title>オイラー法/ホイン法/ルンゲクッタ法をつかった常微分方程式の初期値問題</title><link>https://asashiho.github.io/ordinary-differential-equation/ode/</link><pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/ordinary-differential-equation/ode/</guid><description>ここでは、数値解析の応用分野である構造解析や熱流体解析などのシミュレーションの基本となる、常微分方程式の初期値問題に関する簡単な数値解析を紹介します。
一般に独立変数$x$に関する関数$y$の$m$階常微分方程式はつぎのとおりです。
$$ \dfrac{dy}{dx}=f(x,y,y&amp;rsquo;,y&amp;rsquo;',\cdot \cdot \cdot,y^{m-1}) $$
ここで区間$[a,b]$における$x=a$での$m$個の初期値を与え
$$ y(a)=y_0,; y&amp;rsquo;(a)=y&amp;rsquo;_0,; \cdot \cdot \cdot,y^{(m-1)}(a)= y^{m-1} $$
で関数$y$を求める問題を初期値問題と言います。
ここでもっとも簡単な1階常微分方程式の初期値問題を考えます。
$$ \dfrac{dy}{dx} =f(x,y) $$
ここで$x$の解析領域$[a,b]$を間隔 $h$ で $n=(b-a)/h$ 分割して、$x,x_1,x_2,\cdot \cdot \cdot,x_n$ からなる区分 $i(x_i \leqq x \leqq x_{i+1})$ で積分すると次の式になります。
$$ \int_{x_{i}}^{x_{i+1}} \dfrac {dx}{dx}dx =\int_{x_{i}}^{x_{i+1}} f(x,y) dx $$
これを代数方程式で表すと
$$ y_{i+1} = y_{i} + \int_{x_{i}}^{x_{i+1}} f(x,y) dx $$ となり、初期値$(x_0,y_0)$を与えて順次解くことで近似解が数列${y_i}$として求められます。
この差分式は$h,x_{i},y_{i}$の値を用いた増分関数$k(x_i,y_i,h)$と刻み幅$h$との積として表されます。
$$ y_{i+1} = y_{i} + hk(x_i,y_i,h) $$
このように、厳密解ではなく代数方程式による近似解を求めることを数値解析と呼びます。数値解析は、数学や物理学の分野で代数的な方法で解を得ることが不可能な解析学上の問題を数値を用いて近似的に解くときに用いられ、主に計算機をつかって近似解を求めます。
今回は例題として、以下の常微分方程式
$$ \begin{aligned} \dfrac{dy}{dx} = xy \end{aligned} $$</description></item><item><title>高可用性かつスケーラブルなKubernetesクラスターを運用するときに気を付けたいこと</title><link>https://asashiho.github.io/kube-deschesuler/kube-deschesuler/</link><pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate><guid>https://asashiho.github.io/kube-deschesuler/kube-deschesuler/</guid><description>お仕事でプリセールスをしているため、お客様やSIパートナー様といっしょに「ぜったいにサービスを止められないシステム」について議論することが多くあります。
一方、クラウドはオンプレに比べてスケーラブルな構成をとることが得意です。したがって、ユーザーの利用が時間的にばらつきがあるシステムやスパイクアクセスが発生するシステムなどの場合は、クラウドを提案する良いチャンスだったりもします。
このブログではそのようなニーズを満たすクラスターを運用するときに気を付けたいことや、私自身が検証していて気づいたことをホワイトボードに書く感覚で、だらだらと書きとめます。
なお、本内容はたまたまAzureが提供するKubernetesマネージドサービスである「Azure Kubernetes Service（以下AKS）」を使って検証しましたが、基本的な考え方はやGoogle CloudのGKEやAWSのEKSなど他クラウドでも同じだとおもいます。
クラスターを物理障害から守るアーキテクチャ Kubernetesはシステムのインフラストラクチャー部分の多くを抽象化しオートヒーリングや宣言ベースのデプロイメントが可能で、高可用性なシステム構築を実現することが可能なコンテナオーケストレータです。 が、その土台をささえる物理レイヤーはオンプレミスやクラウドにかかわらず、まじないや祈祷のたぐいで安定稼働しているわけではありません。
多くの場合ハードウエアはデータセンターに収容され、電源/ネットワーク/冷却装置/サーバー/ストレージなどを構成しているため、高可用性システムを構築するにはSPOF（単一障害点）がないようインフラを設計する必要があります。
またサーバー群にインストールするOSで脆弱性やバグなどが発生したときはバージョンアップなどを行う必要もあります。
AzureのAKSはマネージドサービスではありますが、中でKuberntesのNodeをAzureのVMを使って構成しています。AzureのVMの可用性を高める手法として「可用性ゾーン」というものがあります。
ざっくりってしまうと、たとえばAzureの東日本リージョンにはそれぞれ異なる電源/ネットワーク/冷却装置が別々の3つのデータセンター(ゾーン)があります。そのためアプリを3つのデータセンターで分散して動かしておけば、たとえどこかのデータセンター内で障害が発生しても、システムが継続できる可能性が高くなります。
またこの可用性ゾーンは「更新ドメイン」をもっており、メンテナンスや再起動でシステムが停止するリスクを減らすこともできます。
物理的に分散したKubernetesクラスターを作成する AKSには、可用性ゾーンを使用するKuberntesクラスターを作成することができます。この便利機能を使うと、次のようにKuberntesのNodeを分散して配置できます。
いくつかの制限事項がありますが、執筆時点(2020/03)では、次のリージョンの可用性ゾーンが使用できます。東日本リージョンでも利用できます。
米国中部 米国東部2 米国東部 フランス中部 東日本 北ヨーロッパ 東南アジア 英国南部 西ヨーロッパ 米国西部2 ゾーンの停止時、つまりデータセンター丸ごと障害時には、手動またはオートスケーラーを使用してNodeを再調整でき、たとえ1つのゾーンが使用不可になっても、アプリケーションは引き続き実行されます。
AKSクラスターの構築のしかたは公式ドキュメントのとおりですが、ポイントとしては以下のように、az aks createコマンドの引数に--zonesオプションを指定します。これで3つのゾーンにNodeが分散されます。
az aks create \ -g $RG_NAME \ -n $AKS_NAME \ --generate-ssh-keys \ --vm-set-type VirtualMachineScaleSets \ --load-balancer-sku standard \ --node-count 3 \ --zones 1 2 3 ※ 今回は検証のためなので、&amp;ndash;generate-ssh-keysオプションを指定していますが、本番環境ではきちんとSSH Keyを設定してください。
クラスターは約15分ほどで起動します。次のコマンドでNodeが分散されているのを確認してください。3台のNodeが東日本リーションのjapaneast-1/japaneast-2/japaneast-3にそれぞれ1台ずつ配置されているのが分かります。</description></item></channel></rss>